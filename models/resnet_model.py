"""
ResNetäººè„¸è¯†åˆ«æ¨¡å‹å®ç°
"""

import cv2
import numpy as np
import time
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
import torchvision.transforms as transforms
import torchvision.models as models
from torch.cuda import amp

class FaceDataset(Dataset):
    """è‡ªå®šä¹‰PyTorchæ•°æ®é›†ç±»ï¼Œç”¨äºåŠ è½½å½©è‰²äººè„¸å›¾åƒ"""
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        # å½©è‰²å›¾åƒå¤„ç† (H, W, C)
        image = self.images[idx].astype(np.uint8)  # ç¡®ä¿ä¸ºuint8æ ¼å¼
        label = self.labels[idx]
        
        if self.transform:
            # å°†OpenCVå›¾åƒ(BGR)è½¬æ¢ä¸ºPILå›¾åƒ(RGB)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = self.transform(image)
        
        label = torch.tensor(label, dtype=torch.long)
        return image, label

class ResNetFaceRecognizer(nn.Module):
    """
    åŸºäºResNetçš„äººè„¸è¯†åˆ«å™¨ï¼Œæ”¯æŒå½©è‰²å›¾åƒè¾“å…¥
    """
    def __init__(self, num_classes, epochs=150, batch_size=32, learning_rate=0.001):
        super(ResNetFaceRecognizer, self).__init__()
        self.epochs = epochs
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.num_classes = num_classes
        
        # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet18ä½œä¸ºåŸºç¡€æ¨¡å‹
        self.base_model = models.resnet18(pretrained=True)
        
        # ä¿®æ”¹ç¬¬ä¸€å±‚ä»¥é€‚åº”å½©è‰²è¾“å…¥
        self.base_model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        
        # æ›¿æ¢æœ€åä¸€å±‚å…¨è¿æ¥å±‚
        num_features = self.base_model.fc.in_features
        self.base_model.fc = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )
        
        self.to(self.device)
        self.training_time = None
        self.prediction_time = None
        self.train_labels = None
        self.best_val_acc = 0.0
        
    def forward(self, x):
        return self.base_model(x)
    
    def train_model(self, train_images, train_labels, val_images, val_labels):
        """
        è®­ç»ƒæ¨¡å‹ï¼ŒåŒ…å«æ—©åœå’Œå­¦ä¹ ç‡è°ƒåº¦
        """
        print("[INFO] ğŸš€ å¼€å§‹è®­ç»ƒResNetæ¨¡å‹...")
        start_time = time.time()
        
        # æ­¥éª¤1: æ•°æ®é¢„å¤„ç†
        print("\nğŸ“Š æ­¥éª¤ 1/5: æ•°æ®é¢„å¤„ç†")
        n_samples = train_images.shape[0]
        print(f"[INFO] è®­ç»ƒæ ·æœ¬æ•°: {n_samples}")
        print(f"[INFO] å›¾åƒå°ºå¯¸: {train_images.shape[1:]}")
        
        # åˆ›å»ºæ•°æ®å¢å¼º
        train_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((128, 128)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.RandomAffine(0, translate=(0.1, 0.1)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        val_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((128, 128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = FaceDataset(train_images, train_labels, transform=train_transform)
        val_dataset = FaceDataset(val_images, val_labels, transform=val_transform)
        
        # åˆ›å»ºåŠ æƒé‡‡æ ·å™¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        class_counts = np.bincount(train_labels)
        class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)
        sample_weights = class_weights[train_labels]
        sampler = WeightedRandomSampler(
            weights=sample_weights, 
            num_samples=len(sample_weights), 
            replacement=True
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.batch_size, 
            sampler=sampler,
            pin_memory=True
        )
        val_loader = DataLoader(
            val_dataset, 
            batch_size=self.batch_size, 
            shuffle=False,
            pin_memory=True
        )
        
        # æ­¥éª¤2: è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        print("\nğŸ¯ æ­¥éª¤ 2/5: è®¾ç½®æ¨¡å‹å‚æ•°")
        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)
        criterion = nn.CrossEntropyLoss()
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, 
            mode='max', 
            factor=0.5, 
            patience=6,
            verbose=True
        )
        
        # æ··åˆç²¾åº¦è®­ç»ƒçš„æ¢¯åº¦ç¼©æ”¾å™¨
        scaler = amp.GradScaler(enabled=self.device.type == 'cuda')
        
        # æ­¥éª¤3: è®­ç»ƒæ¨¡å‹
        print("\nğŸ¨ æ­¥éª¤ 3/5: è®­ç»ƒæ¨¡å‹")
        best_model_wts = None
        no_improve = 0
        patience = 5
        
        for epoch in range(self.epochs):
            self.train()
            running_loss = 0.0
            running_corrects = 0
            
            with tqdm(total=len(train_loader), desc=f"Epoch {epoch+1}/{self.epochs}", unit="batch") as pbar:
                for images, labels in train_loader:
                    images, labels = images.to(self.device), labels.to(self.device)
                    
                    optimizer.zero_grad()
                    
                    # æ··åˆç²¾åº¦è®­ç»ƒ
                    with amp.autocast(enabled=self.device.type == 'cuda'):
                        outputs = self(images)
                        loss = criterion(outputs, labels)
                        _, preds = torch.max(outputs, 1)
                    
                    scaler.scale(loss).backward()
                    scaler.step(optimizer)
                    scaler.update()
                    
                    running_loss += loss.item() * images.size(0)
                    running_corrects += torch.sum(preds == labels.data)
                    pbar.set_postfix({'loss': f'{loss.item():.4f}'})
                    pbar.update(1)
            
            epoch_loss = running_loss / len(train_dataset)
            epoch_acc = running_corrects.double() / len(train_dataset)
            
            # éªŒè¯é˜¶æ®µ
            val_acc = self.evaluate(val_loader)
            print(f"è®­ç»ƒæŸå¤±: {epoch_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {epoch_acc:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(val_acc)
            
            # æ—©åœæœºåˆ¶
            if val_acc > self.best_val_acc:
                self.best_val_acc = val_acc
                best_model_wts = self.state_dict().copy()
                no_improve = 0
                print(f"ğŸ”¥ æœ€ä½³æ¨¡å‹æ›´æ–°! éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
            else:
                no_improve += 1
                if no_improve >= patience:
                    print(f"â¹ï¸ æ—©åœè§¦å‘: éªŒè¯å‡†ç¡®ç‡è¿ç»­{patience}è½®æœªæå‡")
                    break
        
        # åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡
        if best_model_wts:
            self.load_state_dict(best_model_wts)
        
        self.train_labels = train_labels
        self.training_time = time.time() - start_time
        
        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {self.training_time:.2f}ç§’")
        print(f"ğŸ’¾ è®­ç»ƒæ ·æœ¬æ•°: {n_samples}")
        print(f"ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.4f}")
    
    def evaluate(self, data_loader):
        """è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å‡†ç¡®ç‡"""
        self.eval()
        running_corrects = 0
        
        for images, labels in data_loader:
            images, labels = images.to(self.device), labels.to(self.device)
            
            with torch.no_grad():
                outputs = self(images)
                _, preds = torch.max(outputs, 1)
            
            running_corrects += torch.sum(preds == labels.data)
        
        acc = running_corrects.double() / len(data_loader.dataset)
        return acc.item()
    
    def predict(self, test_images):
        """
        é¢„æµ‹æµ‹è¯•å›¾åƒçš„æ ‡ç­¾
        """
        print("\nğŸ”® å¼€å§‹é¢„æµ‹...")
        start_time = time.time()
        
        n_samples = test_images.shape[0]
        print(f"[INFO] é¢„æµ‹æ ·æœ¬æ•°: {n_samples}")
        
        # é¢„å¤„ç†
        transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((128, 128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        test_dataset = FaceDataset(test_images, np.zeros(n_samples, dtype=np.int64), transform=transform)
        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)
        
        # é¢„æµ‹
        self.eval()
        predicted_labels = []
        
        with torch.no_grad():
            with tqdm(total=len(test_loader), desc="åˆ†ç±»é¢„æµ‹", unit="batch") as pbar:
                for images, _ in test_loader:
                    images = images.to(self.device)
                    outputs = self(images)
                    _, predicted = torch.max(outputs, 1)
                    predicted_labels.extend(predicted.cpu().numpy())
                    pbar.update(1)
        
        self.prediction_time = time.time() - start_time
        
        print(f"\nâœ… é¢„æµ‹å®Œæˆ!")
        print(f"â±ï¸  é¢„æµ‹æ—¶é—´: {self.prediction_time:.2f}ç§’")
        print(f"âš¡  å¹³å‡é¢„æµ‹é€Ÿåº¦: {n_samples/self.prediction_time:.2f} å¼ /ç§’")
        
        return np.array(predicted_labels)
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.parameters())
        return {
            'num_classes': self.num_classes,
            'epochs': self.epochs,
            'batch_size': self.batch_size,
            'learning_rate': self.learning_rate,
            'total_parameters': total_params,
            'training_samples': len(self.train_labels) if self.train_labels is not None else 0,
            'training_time': self.training_time,
            'prediction_time': self.prediction_time,
            'best_val_acc': self.best_val_acc
        }