"""
LBPHäººè„¸è¯†åˆ«æ¨¡å‹å®ç°
"""

import cv2
import numpy as np
import time
from tqdm import tqdm

class EnhancedLBPHRecognizer:
    """
    å¢å¼ºç‰ˆLBPHè¯†åˆ«å™¨
    """
    def __init__(self, radius=1, neighbors=8, grid_x=8, grid_y=8, threshold=100.0):
        """
        åˆå§‹åŒ–LBPHè¯†åˆ«å™¨
        """
        self.radius = radius
        self.neighbors = neighbors
        self.grid_x = grid_x
        self.grid_y = grid_y
        self.threshold = threshold
        self.recognizer = cv2.face.LBPHFaceRecognizer_create(
            radius=radius, neighbors=neighbors, grid_x=grid_x, grid_y=grid_y, threshold=threshold
        )
        self.train_labels = None
        self.training_time = None
        self.prediction_time = None
        
    def train(self, train_images, train_labels):
        """
        è®­ç»ƒLBPHæ¨¡å‹
        """
        print("[INFO] ğŸš€ å¼€å§‹è®­ç»ƒLBPHæ¨¡å‹...")
        start_time = time.time()
        
        # æ­¥éª¤1: æ•°æ®é¢„å¤„ç†
        print("\nğŸ“Š æ­¥éª¤ 1/3: æ•°æ®é¢„å¤„ç†")
        n_samples = train_images.shape[0]
        
        print(f"[INFO] è®­ç»ƒæ ·æœ¬æ•°: {n_samples}")
        print(f"[INFO] å›¾åƒå°ºå¯¸: {train_images.shape[1:]}")
        
        # ç¡®ä¿å›¾åƒä¸ºuint8ç±»å‹
        print("[INFO] è½¬æ¢å›¾åƒæ ¼å¼...")
        images_uint8 = train_images.astype(np.uint8)
        
        # æ­¥éª¤2: è®­ç»ƒLBPHæ¨¡å‹
        print("\nğŸ¯ æ­¥éª¤ 2/3: è®­ç»ƒLBPHæ¨¡å‹")
        print(f"[INFO] ä½¿ç”¨å‚æ•°: radius={self.radius}, neighbors={self.neighbors}, grid_x={self.grid_x}, grid_y={self.grid_y}")
        
        with tqdm(total=100, desc="LBPHè®­ç»ƒ", unit="%") as pbar:
            self.recognizer.train(list(images_uint8), train_labels.astype(np.int32))
            pbar.update(100)
        
        self.train_labels = train_labels
        self.training_time = time.time() - start_time
        
        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {self.training_time:.2f}ç§’")
        print(f"ğŸ’¾ è®­ç»ƒæ•°æ®å½¢çŠ¶: {train_images.shape}")
        
    def predict(self, test_images):
        """
        é¢„æµ‹æµ‹è¯•å›¾åƒçš„æ ‡ç­¾
        """
        if self.recognizer is None:
            raise ValueError("æ¨¡å‹å¿…é¡»å…ˆè®­ç»ƒæ‰èƒ½è¿›è¡Œé¢„æµ‹")
        
        print("\nğŸ”® å¼€å§‹é¢„æµ‹...")
        start_time = time.time()
        
        n_samples = test_images.shape[0]
        print(f"[INFO] é¢„æµ‹æ ·æœ¬æ•°: {n_samples}")
        
        # æ­¥éª¤1: é¢„å¤„ç†æµ‹è¯•å›¾åƒ
        print("\nğŸ“Š æ­¥éª¤ 1/2: é¢„å¤„ç†æµ‹è¯•å›¾åƒ")
        images_uint8 = test_images.astype(np.uint8)
        
        # æ­¥éª¤2: LBPHåˆ†ç±»
        print("\nğŸ¯ æ­¥éª¤ 2/2: LBPHåˆ†ç±»")
        predicted_labels = []
        
        with tqdm(total=n_samples, desc="åˆ†ç±»é¢„æµ‹", unit="å¼ ") as pbar:
            for img in images_uint8:
                label, _ = self.recognizer.predict(img)
                predicted_labels.append(label if label != -1 else 0)  # å¤„ç†æœªçŸ¥
                pbar.update(1)
        
        self.prediction_time = time.time() - start_time
        
        print(f"\nâœ… é¢„æµ‹å®Œæˆ!")
        print(f"â±ï¸  é¢„æµ‹æ—¶é—´: {self.prediction_time:.2f}ç§’")
        print(f"âš¡  å¹³å‡é¢„æµ‹é€Ÿåº¦: {n_samples/self.prediction_time:.2f} å¼ /ç§’")
        
        return np.array(predicted_labels)
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'radius': self.radius,
            'neighbors': self.neighbors,
            'grid_x': self.grid_x,
            'grid_y': self.grid_y,
            'threshold': self.threshold,
            'training_samples': len(self.train_labels) if self.train_labels is not None else 0,
            'training_time': self.training_time,
            'prediction_time': self.prediction_time
        }