"""
æ¨¡å‹éªŒè¯è„šæœ¬
"""

import argparse
import pickle
import os
import warnings
warnings.filterwarnings('ignore')

from config import *
from utils.data_loader import load_dataset_with_split
from utils.evaluation import comprehensive_evaluation, save_results
from utils.visualization import plot_pca_analysis, plot_lda_analysis, plot_performance_metrics, print_quantitative_comparison

def load_model(model_name):
    """åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"""
    model_path = get_model_path(model_name)
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    print(f"ğŸ“‚ å·²åŠ è½½æ¨¡å‹: {model_path}")
    return model

def validate_single_model(model_name, val_images, val_labels, label_map):
    """éªŒè¯å•ä¸ªæ¨¡å‹"""
    print(f"\n{'='*80}")
    print(f"ğŸ” éªŒè¯ {MODEL_MAPPING[model_name]} æ¨¡å‹")
    print('='*80)
    
    try:
        # åŠ è½½æ¨¡å‹
        model = load_model(model_name)
        
        # æ•°æ®ç±»å‹å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        if model_name == 'resnet':
            # ResNetéœ€è¦å½©è‰²å›¾åƒ
            if len(val_images.shape) == 3:  # ç°åº¦å›¾åƒï¼Œéœ€è¦è½¬æ¢
                import cv2
                val_images_color = []
                for img in val_images:
                    color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                    val_images_color.append(color_img)
                val_images = np.array(val_images_color)
        else:
            # å…¶ä»–æ¨¡å‹éœ€è¦ç°åº¦å›¾åƒ
            if len(val_images.shape) == 4:  # å½©è‰²å›¾åƒï¼Œéœ€è¦è½¬æ¢
                import cv2
                val_images_gray = []
                for img in val_images:
                    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                    val_images_gray.append(gray_img)
                val_images = np.array(val_images_gray)
        
        # è¯„ä¼°æ¨¡å‹
        results = comprehensive_evaluation(model, val_images, val_labels, label_map, MODEL_MAPPING[model_name])
        
        # ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡
        if EVALUATION_CONFIG['save_results']:
            plot_performance_metrics(results, MODEL_MAPPING[model_name])
            
            # ç»˜åˆ¶ç‰¹æ®Šåˆ†æå›¾
            if model_name == 'eigenface':
                plot_pca_analysis(model, MODEL_MAPPING[model_name])
            elif model_name == 'fisherface':
                plot_pca_analysis(model, MODEL_MAPPING[model_name])
                plot_lda_analysis(model, MODEL_MAPPING[model_name])
        
        # æ‰“å°å®šé‡ç»“æœ
        print_quantitative_comparison(results, MODEL_MAPPING[model_name])
        
        # ä¿å­˜ç»“æœ
        if EVALUATION_CONFIG['save_results']:
            save_results(results, MODEL_MAPPING[model_name])
        
        print(f"\nâœ… {MODEL_MAPPING[model_name]} æ¨¡å‹éªŒè¯å®Œæˆ!")
        
        return {model_name: results}
        
    except FileNotFoundError as e:
        print(f"âŒ {MODEL_MAPPING[model_name]} æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print(f"ğŸ’¡ è¯·å…ˆè¿è¡Œè®­ç»ƒç¨‹åºæˆ–æ£€æŸ¥æ¨¡å‹è·¯å¾„")
        return {}
    except Exception as e:
        print(f"âŒ {MODEL_MAPPING[model_name]} æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {}

def validate_models(model_names, val_images, val_labels, label_map):
    """éªŒè¯å¤šä¸ªæ¨¡å‹"""
    all_results = {}
    
    for model_name in model_names:
        if model_name in SUPPORTED_MODELS:
            results = validate_single_model(model_name, val_images, val_labels, label_map)
            all_results.update(results)
        else:
            print(f"âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
    
    return all_results

def check_available_models():
    """æ£€æŸ¥å¯ç”¨çš„å·²è®­ç»ƒæ¨¡å‹"""
    available_models = []
    for model_name in SUPPORTED_MODELS:
        model_path = get_model_path(model_name)
        if os.path.exists(model_path):
            available_models.append(model_name)
    
    return available_models

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='éªŒè¯äººè„¸è¯†åˆ«æ¨¡å‹')
    parser.add_argument('--model', type=str, choices=SUPPORTED_MODELS + ['all'],
                       default='all', help='è¦éªŒè¯çš„æ¨¡å‹')
    parser.add_argument('--data_path', type=str, default=DATA_PATH,
                       help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--list_models', action='store_true',
                       help='åˆ—å‡ºå¯ç”¨çš„å·²è®­ç»ƒæ¨¡å‹')
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("ğŸ” äººè„¸è¯†åˆ«æ¨¡å‹éªŒè¯ç¨‹åº")
    print("="*60)
    
    # æ£€æŸ¥å¯ç”¨æ¨¡å‹
    available_models = check_available_models()
    
    if args.list_models:
        print(f"\nğŸ“‹ å¯ç”¨çš„å·²è®­ç»ƒæ¨¡å‹:")
        if available_models:
            for model_name in available_models:
                print(f"   âœ… {MODEL_MAPPING[model_name]} ({model_name})")
        else:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹")
            print("   ğŸ’¡ è¯·å…ˆè¿è¡Œè®­ç»ƒç¨‹åº")
        return
    
    if not available_models:
        print(f"\nâŒ æ²¡æœ‰æ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹")
        print(f"ğŸ’¡ è¯·å…ˆè¿è¡Œè®­ç»ƒç¨‹åº: python train.py")
        return
    
    try:
        # ç¡®å®šè¦éªŒè¯çš„æ¨¡å‹
        if args.model == 'all':
            models_to_validate = available_models
        else:
            if args.model in available_models:
                models_to_validate = [args.model]
            else:
                print(f"âŒ æ¨¡å‹ {args.model} æœªæ‰¾åˆ°")
                print(f"ğŸ’¡ å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
                return
        
        print(f"\nğŸ“‹ éªŒè¯é…ç½®:")
        print(f"   æ¨¡å‹: {', '.join(models_to_validate)}")
        print(f"   æ•°æ®è·¯å¾„: {args.data_path}")
        
        # åŠ è½½æ•°æ®é›†ï¼ˆåªéœ€è¦éªŒè¯é›†ï¼‰
        print(f"\nğŸ“Š åŠ è½½æ•°æ®é›†...")
        data = load_dataset_with_split(
            root_dir=args.data_path,
            image_size=DATA_CONFIG['image_size'],
            test_size=DATA_CONFIG['test_size'],
            random_state=DATA_CONFIG['random_state'],
            data_augmentation=False  # éªŒè¯æ—¶ä¸éœ€è¦æ•°æ®å¢å¼º
        )
        
        train_images, train_labels, val_images, val_labels, label_map = data
        
        print(f"\nâœ… æ•°æ®é›†åŠ è½½å®Œæˆ!")
        print(f"   éªŒè¯é›†: {len(val_images)} å¼ å›¾åƒ")
        print(f"   ç±»åˆ«æ•°: {len(label_map)}")
        
        # éªŒè¯æ¨¡å‹
        all_results = validate_models(models_to_validate, val_images, val_labels, label_map)
        
        print(f"\nğŸ‰ æ‰€æœ‰æ¨¡å‹éªŒè¯å®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {RESULTS_DIR}/")
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœæ‘˜è¦
        if all_results:
            print(f"\nğŸ“Š éªŒè¯ç»“æœæ‘˜è¦:")
            print("-" * 60)
            print(f"{'æ¨¡å‹':<15} {'å‡†ç¡®ç‡':<10} {'F1åˆ†æ•°':<10}")
            print("-" * 60)
            for model_name, results in all_results.items():
                print(f"{MODEL_MAPPING[model_name]:<15} {results['accuracy']:<10.4f} {results['f1_score']:<10.4f}")
            print("-" * 60)
        
    except FileNotFoundError as e:
        print(f"âŒ æ•°æ®é›†é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®é›†è·¯å¾„æ­£ç¡®ï¼Œæ ¼å¼ä¸ºï¼šdata/CelebDataProcessed/")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()