"""
æ¨¡å‹è®­ç»ƒè„šæœ¬
"""

import argparse
import pickle
import time
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from config import *
from models import ResNetFaceRecognizer, EnhancedEigenFaceRecognizer, EnhancedFisherFaceRecognizer, EnhancedLBPHRecognizer
from utils.data_loader import load_dataset_with_split
from utils.evaluation import comprehensive_evaluation, save_results
from utils.visualization import plot_pca_analysis, plot_lda_analysis, plot_performance_metrics, print_quantitative_comparison

def create_model(model_name, num_classes):
    """åˆ›å»ºæŒ‡å®šçš„æ¨¡å‹"""
    if model_name == 'resnet':
        config = get_model_config('resnet')
        return ResNetFaceRecognizer(
            num_classes=num_classes,
            epochs=config['epochs'],
            batch_size=config['batch_size'],
            learning_rate=config['learning_rate']
        )
    elif model_name == 'eigenface':
        config = get_model_config('eigenface')
        return EnhancedEigenFaceRecognizer(
            n_components=config['n_components'],
            variance_ratio=config['variance_ratio'],
            knn_neighbors=config['knn_neighbors']
        )
    elif model_name == 'fisherface':
        config = get_model_config('fisherface')
        return EnhancedFisherFaceRecognizer(
            n_components=config['n_components'],
            variance_ratio=config['variance_ratio'],
            knn_neighbors=config['knn_neighbors']
        )
    elif model_name == 'lbph':
        config = get_model_config('lbph')
        return EnhancedLBPHRecognizer(
            radius=config['radius'],
            neighbors=config['neighbors'],
            grid_x=config['grid_x'],
            grid_y=config['grid_y'],
            threshold=config['threshold']
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")

def save_model(model, model_name):
    """ä¿å­˜æ¨¡å‹"""
    if model_name == 'lbph':
        # LBPHæ¨¡å‹ä½¿ç”¨OpenCVè‡ªå¸¦çš„ä¿å­˜æ–¹æ³•
        model_path = get_model_path(model_name).replace('.pkl', '.yml')
        model.recognizer.save(model_path)  # å‡è®¾modelæœ‰recognizerå±æ€§
        print(f"ğŸ’¾ LBPHæ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    else:
        # å…¶ä»–æ¨¡å‹ä½¿ç”¨pickleä¿å­˜
        model_path = get_model_path(model_name)
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")

def train_single_model(model_name, train_images, train_labels, val_images, val_labels, label_map):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    print(f"\n{'='*80}")
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ {MODEL_MAPPING[model_name]} æ¨¡å‹")
    print('='*80)
    
    # ç¡®å®šæ•°æ®ç±»å‹ï¼ˆResNetéœ€è¦å½©è‰²å›¾åƒï¼Œå…¶ä»–éœ€è¦ç°åº¦å›¾åƒï¼‰
    if model_name == 'resnet':
        # ResNetéœ€è¦å½©è‰²å›¾åƒï¼Œç¡®ä¿æ•°æ®æ˜¯å½©è‰²çš„
        if len(train_images.shape) == 3:  # ç°åº¦å›¾åƒï¼Œéœ€è¦è½¬æ¢
            import cv2
            train_images_color = []
            val_images_color = []
            for img in train_images:
                color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                train_images_color.append(color_img)
            for img in val_images:
                color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                val_images_color.append(color_img)
            train_images = np.array(train_images_color)
            val_images = np.array(val_images_color)
    else:
        # å…¶ä»–æ¨¡å‹éœ€è¦ç°åº¦å›¾åƒ
        if len(train_images.shape) == 4:  # å½©è‰²å›¾åƒï¼Œéœ€è¦è½¬æ¢
            import cv2
            train_images_gray = []
            val_images_gray = []
            for img in train_images:
                gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                train_images_gray.append(gray_img)
            for img in val_images:
                gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                val_images_gray.append(gray_img)
            train_images = np.array(train_images_gray)
            val_images = np.array(val_images_gray)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        num_classes = len(np.unique(train_labels))
        model = create_model(model_name, num_classes)
        
        # è®­ç»ƒæ¨¡å‹
        start_time = time.time()
        if model_name == 'resnet':
            model.train_model(train_images, train_labels, val_images, val_labels)
        else:
            model.train(train_images, train_labels)
        
        training_time = time.time() - start_time
        
        # ä¿å­˜æ¨¡å‹
        if TRAIN_CONFIG['save_models']:
            save_model(model, model_name)
        
        # è¯„ä¼°æ¨¡å‹
        print(f"\nğŸ” è¯„ä¼° {MODEL_MAPPING[model_name]} æ¨¡å‹æ€§èƒ½...")
        results = comprehensive_evaluation(model, val_images, val_labels, label_map, MODEL_MAPPING[model_name])
        
        # ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡
        if TRAIN_CONFIG['save_plots']:
            plot_performance_metrics(results, MODEL_MAPPING[model_name])
            
            # ç»˜åˆ¶ç‰¹æ®Šåˆ†æå›¾
            if model_name == 'eigenface':
                plot_pca_analysis(model, MODEL_MAPPING[model_name])
            elif model_name == 'fisherface':
                plot_pca_analysis(model, MODEL_MAPPING[model_name])
                plot_lda_analysis(model, MODEL_MAPPING[model_name])
        
        # æ‰“å°å®šé‡ç»“æœ
        print_quantitative_comparison(results, MODEL_MAPPING[model_name])
        
        # ä¿å­˜ç»“æœ
        if TRAIN_CONFIG['save_reports']:
            save_results(results, MODEL_MAPPING[model_name])
        
        print(f"\nâœ… {MODEL_MAPPING[model_name]} æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {training_time/60:.2f} åˆ†é’Ÿ")
        
        return {model_name: results}
        
    except Exception as e:
        print(f"âŒ {MODEL_MAPPING[model_name]} æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {}

def train_models(model_names, train_images, train_labels, val_images, val_labels, label_map):
    """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
    all_results = {}
    
    for model_name in model_names:
        if model_name in SUPPORTED_MODELS:
            results = train_single_model(model_name, train_images, train_labels, val_images, val_labels, label_map)
            all_results.update(results)
        else:
            print(f"âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
    
    return all_results

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='è®­ç»ƒäººè„¸è¯†åˆ«æ¨¡å‹')
    parser.add_argument('--model', type=str, choices=SUPPORTED_MODELS + ['all'],
                       default='all', help='è¦è®­ç»ƒçš„æ¨¡å‹')
    parser.add_argument('--data_path', type=str, default=DATA_PATH,
                       help='æ•°æ®é›†è·¯å¾„')
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("ğŸ¯ äººè„¸è¯†åˆ«æ¨¡å‹è®­ç»ƒç¨‹åº")
    print("="*60)
    
    try:
        # ç¡®å®šè¦è®­ç»ƒçš„æ¨¡å‹
        if args.model == 'all':
            models_to_train = SUPPORTED_MODELS
        else:
            models_to_train = [args.model]
        
        print(f"\nğŸ“‹ è®­ç»ƒé…ç½®:")
        print(f"   æ¨¡å‹: {', '.join(models_to_train)}")
        print(f"   æ•°æ®è·¯å¾„: {args.data_path}")
        
        # åŠ è½½æ•°æ®é›†
        print(f"\nğŸ“Š åŠ è½½æ•°æ®é›†...")
        data = load_dataset_with_split(
            root_dir=args.data_path,
            image_size=DATA_CONFIG['image_size'],
            test_size=DATA_CONFIG['test_size'],
            random_state=DATA_CONFIG['random_state'],
            data_augmentation=TRAIN_CONFIG['data_augmentation']
        )
        
        train_images, train_labels, val_images, val_labels, label_map = data
        
        print(f"\nâœ… æ•°æ®é›†åŠ è½½å®Œæˆ!")
        print(f"   è®­ç»ƒé›†: {len(train_images)} å¼ å›¾åƒ")
        print(f"   éªŒè¯é›†: {len(val_images)} å¼ å›¾åƒ")
        print(f"   ç±»åˆ«æ•°: {len(label_map)}")
        
        # è®­ç»ƒæ¨¡å‹
        start_time = time.time()
        all_results = train_models(models_to_train, train_images, train_labels, val_images, val_labels, label_map)
        total_time = time.time() - start_time
        
        print(f"\nğŸ‰ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {total_time/60:.2f} åˆ†é’Ÿ")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {RESULTS_DIR}/")
        
    except FileNotFoundError as e:
        print(f"âŒ æ•°æ®é›†é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®é›†è·¯å¾„æ­£ç¡®ï¼Œæ ¼å¼ä¸ºï¼šdata/CelebDataProcessed/")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()